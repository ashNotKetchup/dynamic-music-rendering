# Proposal

1. Dynamic, algorithmically and reflexive generative scores (DARGS)
2. Single project route. There is a single theme I’d like to explore, however, I envisage that this will include a portfolio of the works created during the course of the project as well
3. Music, computing, and visuals tend to fall into a number of categories:
   1. Audio generated from computational rules
   2. Audio generated from scores generated by computational rules
   3. Visuals generated by computational rules
   4. Visuals generated by audio input via some computational rule
   5. Audio generated from visual input via some computational rule (data sonification)

4. Since I come from a background of composition for improvised and aleatoric computer musics, I am frustrated by the lack of feedback loops between the compositional and group performance dynamics. I want to explore the ways computers can be utilised to reflexively generate graphic/system-based scores, responding to and shaping music in real-time. This work cumulates in a number of generative compositional systems, as well as potentially, a performance.



5. Context/Background:

   1. Interactive n Generative music (L…markov….)
   2. Image GANs/generative n parametric images…
   3. Sonification of boids for group performance dynamics


6. Skills survey: 
   
   1. Compositional:
      1. Simple algorithmic composition
      2. Stochastic methods
      3. UI/UX design
      4. Unpacking and arranging musical ideas
   2. Technical:
      1. Integration of max/msp with javascript (I have experience in both, more max than JS, but I have little to no experience combining the two)
      2. Machine listening
      3. Jitter Visuals

7. Research Questions:
   
   1. How can we meaningfully represent group play dynamics and create musical games with visual/rule-based information? Can these dynamics be shifted over time?
      1. With instruction-based scores such as Artificial Life, can a computer be trained to understand which instruction is being played?
   
   2. Can we abstract markov/L chains to higher-level concepts like melodic contour etc?
      1. How does this typically relate to graphic scores?
      2. How does this work for sample-based instruments and notations (eg: [solitude](https://www.youtube.com/watch?v=6wPUGFUoZ7A))
      3. Can these abstractions then be modulated? For the most simple example, can we take a markov chain and modulate its key/mode? In more abstract terms, what does it mean to modulate an idea/set of ideas such as “upwards then downward scoop” or even further “listen to the person next to you”?
8. Methodology: HOW will you work towards achieving your goals?
   1. Working with musicians I have performed with in this capacity before, I will start by examining the creative and communicative capacity of existing methods.
      1. Experiment with co-compositional methods between a single musician and max
      2. Experiment in taking what would be sound expression from max and representing it meaningfully for another musician to enact.
      3. Make the system bidirectional
      4. Experiment with feedback loops, different inputs, and different players
   2. I will iteratively develop tools based on these workshops, focusing on a rotation of themes surrounding graphic scores, computational thinking, etc...
9. Key References (Bibliography, List of works): 
   1. Graphic Scores:
      1. The work of Iannis Xenakis, Corbusier ([Phillips Pavillion](https://www.youtube.com/watch?v=P-a5UUiyyWY))
      2. Solitude (steiner)
   2. Systematic Scores:
      1. George e stone’s artificial life
   3. Analysis and sonification:
      1. Flucoma
      2. (Roads) granular
      3. Markov chain/machine listening
